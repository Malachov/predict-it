
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>padasip.preprocess.lda &#8212; predictit 0.22 documentation</title>
    <link rel="stylesheet" href="../../../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
   
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for padasip.preprocess.lda</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">.. versionadded:: 0.6</span>

<span class="sd">Linear discriminant analysis (LDA) :cite:`fisher1936use`</span>
<span class="sd">is a method used to determine the features</span>
<span class="sd">that separates some classes of items. The output of LDA may be used as</span>
<span class="sd">a linear classifier, or for dimensionality reduction for purposes of</span>
<span class="sd">classification.</span>

<span class="sd">.. contents::</span>
<span class="sd">   :local:</span>
<span class="sd">   :depth: 1</span>
<span class="sd">   </span>
<span class="sd">See also: :ref:`preprocess-pca`</span>

<span class="sd">Usage Explanation</span>
<span class="sd">********************</span>

<span class="sd">For reduction of data-set :code:`x` with labels stored in array (:code:`labels`)</span>
<span class="sd">to new dataset :code:`new_x` containg just :code:`n` number of</span>
<span class="sd">columns</span>

<span class="sd">.. code-block:: python</span>

<span class="sd">    new_x = pa.preprocess.LDA(x, labels, n) </span>
<span class="sd">    </span>
<span class="sd">The sorted array of scattermatrix eigenvalues for dataset :code:`x` described</span>
<span class="sd">with variable :code:`labels` can be obtained as follows</span>
<span class="sd">    </span>
<span class="sd">.. code-block:: python</span>

<span class="sd">    eigenvalues = pa.preprocess.LDA_discriminants(x, labels) </span>
<span class="sd">    </span>

<span class="sd">Minimal Working Examples</span>
<span class="sd">*****************************</span>

<span class="sd">In this example we create data-set :code:`x` of 150 random samples. Every sample</span>
<span class="sd">is described by 4 values and label. The labels are stored in </span>
<span class="sd">array :code:`labels`.</span>

<span class="sd">Firstly, it is good to see the eigenvalues of scatter matrix to determine</span>
<span class="sd">how many rows is reasonable to reduce </span>

<span class="sd">.. code-block:: python</span>

<span class="sd">    import numpy as np</span>
<span class="sd">    import padasip as pa</span>

<span class="sd">    np.random.seed(100) # constant seed to keep the results consistent</span>

<span class="sd">    N = 150 # number of samples</span>
<span class="sd">    classes = np.array([&quot;1&quot;, &quot;a&quot;, 3]) # names of classes</span>
<span class="sd">    cols = 4 # number of features (columns in dataset)</span>

<span class="sd">    x = np.random.random((N, cols)) # random data</span>
<span class="sd">    labels = np.random.choice(classes, size=N) # random labels</span>

<span class="sd">    print pa.preprocess.LDA_discriminants(x, labels)</span>

<span class="sd">what prints</span>

<span class="sd">&gt;&gt;&gt; [  2.90863957e-02   2.28352079e-02   1.23545720e-18  -1.61163011e-18]</span>

<span class="sd">From this output it is obvious that reasonable number of columns to keep is 2.</span>
<span class="sd">The following code reduce the number of features to 2.</span>

<span class="sd">.. code-block:: python</span>

<span class="sd">    import numpy as np</span>
<span class="sd">    import padasip as pa</span>
<span class="sd">    </span>
<span class="sd">    np.random.seed(100) # constant seed to keep the results consistent</span>

<span class="sd">    N = 150 # number of samples</span>
<span class="sd">    classes = np.array([&quot;1&quot;, &quot;a&quot;, 3]) # names of classes</span>
<span class="sd">    cols = 4 # number of features (columns in dataset)</span>

<span class="sd">    x = np.random.random((N, cols)) # random data</span>
<span class="sd">    labels = np.random.choice(classes, size=N) # random labels</span>

<span class="sd">    new_x = pa.preprocess.LDA(x, labels, n=2)</span>

<span class="sd">to check if the size of new data-set is really correct we can print the shapes</span>
<span class="sd">as follows      </span>

<span class="sd">&gt;&gt;&gt; print &quot;Shape of original dataset: {}&quot;.format(x.shape) </span>
<span class="sd">Shape of original dataset: (150, 4)</span>
<span class="sd">&gt;&gt;&gt; print &quot;Shape of new dataset: {}&quot;.format(new_x.shape)</span>
<span class="sd">Shape of new dataset: (150, 2)</span>

<span class="sd">References</span>
<span class="sd">***************</span>

<span class="sd">.. bibliography:: lda.bib</span>
<span class="sd">    :style: plain</span>

<span class="sd">Code Explanation</span>
<span class="sd">***************** </span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">__future__</span> <span class="k">import</span> <span class="n">division</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<div class="viewcode-block" id="LDA_base"><a class="viewcode-back" href="../../../padasip.preprocess.html#padasip.preprocess.lda.LDA_base">[docs]</a><span class="k">def</span> <span class="nf">LDA_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base function used for Linear Discriminant Analysis.</span>

<span class="sd">    **Args:**</span>

<span class="sd">    * `x` : input matrix (2d array), every row represents new sample</span>

<span class="sd">    * `labels` : list of labels (iterable), every item should be label for \</span>
<span class="sd">      sample with corresponding index</span>

<span class="sd">    **Returns:**</span>
<span class="sd">    </span>
<span class="sd">    * `eigenvalues`, `eigenvectors` : eigenvalues and eigenvectors \</span>
<span class="sd">      from LDA analysis </span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">labels</span><span class="p">)))</span>
    <span class="n">cols</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="c1"># mean values for every class</span>
    <span class="n">means</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">classes</span><span class="p">),</span> <span class="n">cols</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">cl</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">classes</span><span class="p">):</span>
        <span class="n">means</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">labels</span><span class="o">==</span><span class="n">cl</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># scatter matrices</span>
    <span class="n">scatter_within</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">cols</span><span class="p">,</span> <span class="n">cols</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">cl</span><span class="p">,</span> <span class="n">mean</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="n">means</span><span class="p">):</span>
        <span class="n">scatter_class</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">cols</span><span class="p">,</span> <span class="n">cols</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">x</span><span class="p">[</span><span class="n">labels</span> <span class="o">==</span> <span class="n">cl</span><span class="p">]:</span>
            <span class="n">dif</span> <span class="o">=</span> <span class="n">row</span> <span class="o">-</span> <span class="n">mean</span>
            <span class="n">scatter_class</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dif</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">cols</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dif</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">cols</span><span class="p">))</span>
        <span class="n">scatter_within</span> <span class="o">+=</span> <span class="n">scatter_class</span>
    <span class="n">total_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">scatter_between</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">cols</span><span class="p">,</span> <span class="n">cols</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">cl</span><span class="p">,</span> <span class="n">mean</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">classes</span><span class="p">,</span> <span class="n">means</span><span class="p">):</span>
        <span class="n">dif</span> <span class="o">=</span> <span class="n">mean</span> <span class="o">-</span> <span class="n">total_mean</span>
        <span class="n">dif_product</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dif</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">cols</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dif</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">cols</span><span class="p">))</span>
        <span class="n">scatter_between</span> <span class="o">+=</span> <span class="n">x</span><span class="p">[</span><span class="n">labels</span> <span class="o">==</span> <span class="n">cl</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">dif_product</span>
    <span class="c1"># eigenvalues and eigenvectors from scatter matrices</span>
    <span class="n">scatter_product</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">scatter_within</span><span class="p">),</span> <span class="n">scatter_between</span><span class="p">)</span>
    <span class="n">eigen_values</span><span class="p">,</span> <span class="n">eigen_vectors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">eig</span><span class="p">(</span><span class="n">scatter_product</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">eigen_values</span><span class="p">,</span> <span class="n">eigen_vectors</span></div>

<div class="viewcode-block" id="LDA"><a class="viewcode-back" href="../../../padasip.preprocess.html#padasip.preprocess.lda.LDA">[docs]</a><span class="k">def</span> <span class="nf">LDA</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Linear Discriminant Analysis function.</span>

<span class="sd">    **Args:**</span>

<span class="sd">    * `x` : input matrix (2d array), every row represents new sample</span>

<span class="sd">    * `labels` : list of labels (iterable), every item should be label for \</span>
<span class="sd">      sample with corresponding index</span>

<span class="sd">    **Kwargs:**</span>

<span class="sd">    * `n` : number of features returned (integer) - how many columns </span>
<span class="sd">      should the output keep</span>

<span class="sd">    **Returns:**</span>
<span class="sd">    </span>
<span class="sd">    * new_x : matrix with reduced size (number of columns are equal `n`)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># select n if not provided</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">n</span><span class="p">:</span>
        <span class="n">n</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span> 
    <span class="c1"># validate inputs</span>
    <span class="k">try</span><span class="p">:</span>    
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Impossible to convert x to a numpy array.&#39;</span><span class="p">)</span>
    <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">==</span> <span class="nb">int</span><span class="p">,</span> <span class="s2">&quot;Provided n is not an integer.&quot;</span>
    <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="n">n</span><span class="p">,</span> <span class="s2">&quot;The requested n is bigger than </span><span class="se">\</span>
<span class="s2">        number of features in x.&quot;</span>
    <span class="c1"># make the LDA</span>
    <span class="n">eigen_values</span><span class="p">,</span> <span class="n">eigen_vectors</span> <span class="o">=</span> <span class="n">LDA_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="c1"># sort the eigen vectors according to eigen values</span>
    <span class="n">eigen_order</span> <span class="o">=</span> <span class="n">eigen_vectors</span><span class="o">.</span><span class="n">T</span><span class="p">[(</span><span class="o">-</span><span class="n">eigen_values</span><span class="p">)</span><span class="o">.</span><span class="n">argsort</span><span class="p">()]</span>
    <span class="k">return</span> <span class="n">eigen_order</span><span class="p">[:</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span></div>


<div class="viewcode-block" id="LDA_discriminants"><a class="viewcode-back" href="../../../padasip.preprocess.html#padasip.preprocess.lda.LDA_discriminants">[docs]</a><span class="k">def</span> <span class="nf">LDA_discriminants</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Linear Discriminant Analysis helper for determination how many columns of</span>
<span class="sd">    data should be reduced.</span>

<span class="sd">    **Args:**</span>

<span class="sd">    * `x` : input matrix (2d array), every row represents new sample</span>

<span class="sd">    * `labels` : list of labels (iterable), every item should be label for \</span>
<span class="sd">        sample with corresponding index</span>

<span class="sd">    **Returns:**</span>
<span class="sd">    </span>
<span class="sd">    * `discriminants` : array of eigenvalues sorted in descending order</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># validate inputs</span>
    <span class="k">try</span><span class="p">:</span>    
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Impossible to convert x to a numpy array.&#39;</span><span class="p">)</span>
    <span class="c1"># make the LDA</span>
    <span class="n">eigen_values</span><span class="p">,</span> <span class="n">eigen_vectors</span> <span class="o">=</span> <span class="n">LDA_base</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">eigen_values</span><span class="p">[(</span><span class="o">-</span><span class="n">eigen_values</span><span class="p">)</span><span class="o">.</span><span class="n">argsort</span><span class="p">()]</span></div>

</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../index.html">predictit</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../index.html">Documentation overview</a><ul>
  <li><a href="../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Daniel Malachov.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.2.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
    </div>

    

    
  </body>
</html>